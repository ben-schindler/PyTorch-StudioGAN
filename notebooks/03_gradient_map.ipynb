{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f95927d5-bfd7-43fe-9a12-d7595bfd78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import main\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import config\n",
    "import utils.ckpt as ckpt\n",
    "import utils.misc as misc\n",
    "import models.model as model\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ca815ec-db97-4453-8602-7f87fe3c379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_batch_image_gradients(generator, discriminator, z_dim, num_classes, batch_size=64, device='cuda'):\n",
    "    \"\"\"\n",
    "    Compute gradients from each discriminator with respect to a batch of fake images.\n",
    "    \n",
    "    Args:\n",
    "        generator: The generator model\n",
    "        discriminator: The discriminator model (ensemble)\n",
    "        z_dim: Dimension of the latent space\n",
    "        num_classes: Number of classes\n",
    "        batch_size: Batch size to use (matching evaluation code)\n",
    "        device: Device to use ('cuda' or 'cpu')\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing fake images, discriminator outputs, and gradients\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set models to eval mode\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    \n",
    "    # Generate random latent vectors\n",
    "    z = torch.randn(batch_size, z_dim, device=device)\n",
    "    \n",
    "    # Generate random class labels\n",
    "    fake_labels = torch.randint(0, num_classes, (batch_size,), device=device)\n",
    "    \n",
    "    # Generate the images\n",
    "    with torch.no_grad():\n",
    "        if hasattr(generator, 'module'):\n",
    "            fake_images = generator.module(z, fake_labels)\n",
    "        else:\n",
    "            fake_images = generator(z, fake_labels)\n",
    "    \n",
    "    # Compute discriminator outputs and gradients\n",
    "    D_outs = []\n",
    "    fake_grads = []\n",
    "    \n",
    "    # Enable gradients for the fake images\n",
    "    fake_images.requires_grad_(True)\n",
    "    \n",
    "    # Check if discriminator has discriminators attribute (ensemble)\n",
    "    if hasattr(discriminator, 'discriminators'):\n",
    "        discriminators = discriminator.discriminators\n",
    "    else:\n",
    "        # If single discriminator, wrap in a list\n",
    "        discriminators = [discriminator]\n",
    "    \n",
    "    # Get discriminator outputs and gradients\n",
    "    for i, discr in enumerate(discriminators):\n",
    "        # Forward pass\n",
    "        D_out = discr(fake_images, fake_labels)[\"adv_output\"]\n",
    "        \n",
    "        # Compute mean of discriminator outputs across the batch\n",
    "        D_out_mean = D_out.mean()\n",
    "        D_outs.append(D_out_mean.item())\n",
    "        \n",
    "        # Compute gradient\n",
    "        fake_images.grad = None  # Clear previous gradients\n",
    "        D_out_mean.backward(retain_graph=True)\n",
    "        \n",
    "        # Save gradient\n",
    "        current_grad = fake_images.grad.clone()\n",
    "        fake_grads.append(current_grad.detach().cpu().numpy())\n",
    "    \n",
    "    return {\n",
    "        'images': fake_images.detach().cpu(),\n",
    "        'labels': fake_labels.detach().cpu(),\n",
    "        'D_outs': D_outs,\n",
    "        'gradients': fake_grads\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_gradient_statistics(results):\n",
    "    \"\"\"\n",
    "    Analyze and compare gradient statistics across discriminators and images.\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary from compute_batch_image_gradients\n",
    "    \n",
    "    Returns:\n",
    "        dict: Statistics about the gradients\n",
    "    \"\"\"    \n",
    "    gradients = results['gradients']\n",
    "    stats = {}\n",
    "    \n",
    "    # Overall statistics for each discriminator\n",
    "    for i, grad in enumerate(gradients):\n",
    "        stats[f'disc_{i}_mean_abs_grad'] = np.abs(grad).mean()\n",
    "        stats[f'disc_{i}_std_abs_grad'] = np.abs(grad).std()\n",
    "        stats[f'disc_{i}_max_abs_grad'] = np.abs(grad).max()\n",
    "        \n",
    "        # Per-channel statistics\n",
    "        for c in range(3):\n",
    "            stats[f'disc_{i}_channel_{c}_mean_abs_grad'] = np.abs(grad[:, c]).mean()\n",
    "    \n",
    "    # Compute inter-discriminator correlation\n",
    "    if len(gradients) > 1:\n",
    "        for i in range(len(gradients)):\n",
    "            for j in range(i+1, len(gradients)):\n",
    "                grad_i_flat = np.abs(gradients[i]).reshape(gradients[i].shape[0], -1)\n",
    "                grad_j_flat = np.abs(gradients[j]).reshape(gradients[j].shape[0], -1)\n",
    "                \n",
    "                # Compute correlation across all dimensions\n",
    "                corr = np.corrcoef(grad_i_flat.mean(axis=1), grad_j_flat.mean(axis=1))[0, 1]\n",
    "                stats[f'disc_{i}_{j}_correlation'] = corr\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "def visualize_batch_gradients(results, sample_idx=0, channel_idx=0, save_path='./batch_gradients'):\n",
    "    \"\"\"\n",
    "    Visualize gradients for a specific image from the batch and a specific channel.\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary from compute_batch_image_gradients\n",
    "        sample_idx: Index of the sample image to visualize\n",
    "        channel_idx: Index of the color channel to visualize (0=Red, 1=Green, 2=Blue)\n",
    "        save_path: Directory to save visualizations\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    # Make sure sample_idx is valid\n",
    "    if sample_idx >= len(results['images']):\n",
    "        raise ValueError(f\"Sample index {sample_idx} out of range (batch size: {len(results['images'])})\")\n",
    "    \n",
    "    # Make sure channel_idx is valid\n",
    "    if channel_idx not in [0, 1, 2]:\n",
    "        raise ValueError(f\"Channel index must be 0 (Red), 1 (Green), or 2 (Blue), got {channel_idx}\")\n",
    "    \n",
    "    images = results['images']\n",
    "    gradients = results['gradients']\n",
    "    D_outs = results['D_outs']\n",
    "    \n",
    "    channel_names = ['Red', 'Green', 'Blue']\n",
    "    channel_cmaps = ['Reds', 'Greens', 'Blues']  # Channel-specific colormaps\n",
    "    \n",
    "    # Convert the image from [-1, 1] to [0, 255] uint8 format\n",
    "    img = images[sample_idx].numpy().transpose(1, 2, 0)\n",
    "    img = np.clip((img + 1) / 2.0 * 255, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Create a figure with 2 + len(discriminators) subplots\n",
    "    num_discs = len(gradients)\n",
    "    fig, axes = plt.subplots(1, 2 + num_discs, figsize=(5 * (2 + num_discs), 5))\n",
    "    \n",
    "    # 1. Plot the RGB image\n",
    "    axes[0].imshow(img)\n",
    "    #axes[0].set_title(f\"Generated Image\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # 2. Plot the selected channel only\n",
    "    channel_img = np.zeros_like(img)\n",
    "    channel_img[:, :, channel_idx] = img[:, :, channel_idx]\n",
    "    axes[1].imshow(channel_img)\n",
    "    #axes[1].set_title(f\"{channel_names[channel_idx]} Channel Features\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # 3. Plot gradient maps for the selected channel for each discriminator\n",
    "    cmap = channel_cmaps[channel_idx]  # Use the channel-specific colormap\n",
    "    \n",
    "    # Plot each discriminator's gradient with its own maximum, but all starting at 0\n",
    "    for disc_idx in range(num_discs):\n",
    "        grad = gradients[disc_idx][sample_idx][channel_idx]\n",
    "        abs_grad = np.abs(grad)\n",
    "        \n",
    "        # Set vmin to 0 (white) and vmax to the maximum value for this gradient\n",
    "        vmin = 0\n",
    "        vmax = abs_grad.max()\n",
    "        \n",
    "        im = axes[2 + disc_idx].imshow(abs_grad, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        axes[2 + disc_idx].set_title(f\"Discriminator {disc_idx}\")\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=axes[2 + disc_idx], shrink=0.8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, f'sample_{sample_idx}_{channel_names[channel_idx]}_channel_gradients.pdf'), dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "51537a99-cbf7-4664-8d0c-8e8c6f93fe8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from step 74000\n"
     ]
    }
   ],
   "source": [
    "#### Initialize configuration with your config file\n",
    "config_path = '../src/configs/CIFAR10-Ensemble/DCGAN-ens-3-ew3.yaml'\n",
    "cfgs = config.Configurations(config_path)\n",
    "\n",
    "# Path to your checkpoint directory\n",
    "ckpt_dir = '../logs/CIFAR10-Ensemble-trash/checkpoints/CIFAR10-DCGAN-ens-3-ew3-train-2024_06_06_15_10_31/'\n",
    "\n",
    "run_configs = {\n",
    "    'ckpt_dir': ckpt_dir,\n",
    "    'mixed_precision': False,  # Set this to match your training settings\n",
    "    'train': False,  # We're not training, just loading a checkpoint\n",
    "    'distributed_data_parallel': False,\n",
    "    'seed': 42,\n",
    "    'cfg_file': config_path,\n",
    "    'freezeD': -1,\n",
    "    'langevin_sampling': False\n",
    "    # Add other run-time configurations as needed\n",
    "}\n",
    "\n",
    "# Update the configuration\n",
    "cfgs.update_cfgs(run_configs, super=\"RUN\")\n",
    "\n",
    "# Create model instances\n",
    "Gen, Gen_mapping, Gen_synthesis, Dis, Gen_ema, Gen_ema_mapping, Gen_ema_synthesis, ema = model.load_generator_discriminator(\n",
    "    DATA=cfgs.DATA,\n",
    "    OPTIMIZATION=cfgs.OPTIMIZATION,\n",
    "    MODEL=cfgs.MODEL,\n",
    "    STYLEGAN=cfgs.STYLEGAN,\n",
    "    MODULES=cfgs.MODULES,\n",
    "    RUN=cfgs.RUN,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    logger=None\n",
    ")\n",
    "\n",
    "# Define optimizers (needed for loading checkpoint)\n",
    "cfgs.define_optimizer(Gen, Dis)\n",
    "\n",
    "# Load checkpoint\n",
    "run_name, step, epoch, topk, aa_p, best_step, best_fid, best_ckpt_path, lecam_emas, logger = ckpt.load_StudioGAN_ckpts(\n",
    "    ckpt_dir=ckpt_dir,\n",
    "    load_best=True,  # Set to True if you want to load the best checkpoint\n",
    "    Gen=Gen,\n",
    "    Dis=Dis,\n",
    "    g_optimizer=cfgs.OPTIMIZATION.g_optimizer,\n",
    "    d_optimizer=cfgs.OPTIMIZATION.d_optimizer,\n",
    "    run_name=\"test\",\n",
    "    apply_g_ema=cfgs.MODEL.apply_g_ema,\n",
    "    Gen_ema=Gen_ema,\n",
    "    ema=ema,\n",
    "    is_train=False,\n",
    "    RUN=cfgs.RUN,\n",
    "    logger=None,\n",
    "    global_rank=0,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    cfg_file=cfgs.RUN.cfg_file\n",
    ")\n",
    "\n",
    "# Now you have loaded models ready to use\n",
    "print(f\"Loaded checkpoint from step {step}\")\n",
    "\n",
    "# Ensure generator is in eval mode\n",
    "generator = Gen_ema if cfgs.MODEL.apply_g_ema and Gen_ema is not None else Gen\n",
    "generator.eval()\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f73ac80-19d9-4db4-a397-38f812fca273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disc_0_mean_abs_grad: 0.001772\n",
      "disc_0_std_abs_grad: 0.001734\n",
      "disc_0_max_abs_grad: 0.025737\n",
      "disc_0_channel_0_mean_abs_grad: 0.001957\n",
      "disc_0_channel_1_mean_abs_grad: 0.001722\n",
      "disc_0_channel_2_mean_abs_grad: 0.001639\n",
      "disc_1_mean_abs_grad: 0.018019\n",
      "disc_1_std_abs_grad: 0.029191\n",
      "disc_1_max_abs_grad: 0.563287\n",
      "disc_1_channel_0_mean_abs_grad: 0.025705\n",
      "disc_1_channel_1_mean_abs_grad: 0.005081\n",
      "disc_1_channel_2_mean_abs_grad: 0.023272\n",
      "disc_2_mean_abs_grad: 0.002806\n",
      "disc_2_std_abs_grad: 0.002696\n",
      "disc_2_max_abs_grad: 0.045883\n",
      "disc_2_channel_0_mean_abs_grad: 0.002962\n",
      "disc_2_channel_1_mean_abs_grad: 0.002693\n",
      "disc_2_channel_2_mean_abs_grad: 0.002762\n",
      "disc_0_1_correlation: 0.105877\n",
      "disc_0_2_correlation: -0.063537\n",
      "disc_1_2_correlation: -0.099517\n"
     ]
    }
   ],
   "source": [
    "# Run the batch gradient computation\n",
    "batch_results = compute_batch_image_gradients(\n",
    "    generator=generator,\n",
    "    discriminator=Dis,\n",
    "    z_dim=cfgs.MODEL.z_dim,\n",
    "    num_classes=cfgs.DATA.num_classes,\n",
    "    batch_size=64,  # Match the batch size in the metrics code\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Analyze gradient statistics\n",
    "stats = analyze_gradient_statistics(batch_results)\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "88a790ba-f41a-4ab6-96c5-064ef950b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize gradients for a few images\n",
    "visualize_batch_gradients(\n",
    "    batch_results, \n",
    "    sample_idx=13, \n",
    "    channel_idx=0,  # 0=Red, 1=Green, 2=Blue\n",
    "    save_path='./03_gradient_map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3064230-b2eb-413a-8fb1-5f02e50c0920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StudioGAN",
   "language": "python",
   "name": "studiogan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
